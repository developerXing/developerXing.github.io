---
layout:     post
title:      环境搭建和集群部署汇总
subtitle:   虚拟机配置
date:       2017-12-5
author:     Corliss
header-img: img/home-bg-o.jpg
catalog: true
tags:
    - 集群
    
---

#### 前言
>linux命令大全http://man.linuxde.net/

# 一.虚拟机配置

## 1.安装完虚拟机之后 ifconfig  发现没有ip地址

1.	执行命令:cd /etc/sysconfig/network-scripts/
         vi ifcfg-eth0
把ONBOOT改成yes
保存 :  wq

2.	执行 : service network restart
3.	ifconfig看看是否有ip了

## 2.怎么把虚拟机IP设置为固定IP

1.执行命令:cd /etc/sysconfig/network-scripts/
         vi ifcfg-eth0

![](https://i.imgur.com/ATvIAE0.jpg)

把BOOTTPROTO改为static
加上:
IPADDR=该虚拟机的当前IP
NETMASK=255.255.255.0
GATEWAY=查看虚拟机当前网关

BOOTTPROTO:static
IPADDR=192.168.
NETMASK=255.255.255.0
GATEWAY=192.168.121.2

执行 : service network restart
ifconfig看看是否有ip了

怎么看当前网关?

编辑->虚拟网络编辑器->点击vmnet8->NAT设置->查看网关IP

![](https://i.imgur.com/RWfICbp.jpg)

![](https://i.imgur.com/TpLVA3N.jpg)
	
	DEVICE=eth0
	TYPE=Ethernet
	UUID=26d2054c-f3a9-487f-b467-bd5f304cbeed
	ONBOOT=yes
	NM_CONTROLLED=yes
	BOOTPROTO=static
	HWADDR=00:0C:29:43:72:6C
	DEFROUTE=yes
	PEERDNS=yes
	PEERROUTES=yes
	IPV4_FAILURE_FATAL=yes
	IPV6INIT=no
	NAME="System eth0"

## 3.配置JAVA 的 JDK

	第一步:
	创建放置JDK的两个文件夹
	mkdir –p /export/servers
	mkdir –p /export/software
	rz
	发现没法上传
	
	于是安装lrzsz:
	yum install lrzsz 
	
	输入两次y
	
	然后:
	rz
	自动跳出一个窗口,选择JDK的压缩包文件
	上传成功
	ll 发现一个JDK,复制压缩包名称
	解压JDK到/export/servers:目录下 
	tar –zxvf JDK压缩包名 –C /export/servers
	CD到export/servers目录下:
	cd / export/servers/
	ll
	看到解压后的JDK
	然后移动一下:
	mv 解压后的JDK名/ jdk
	
	最后进行环境配置:
	vi /etc/profile
	
	把以下配置文件复制到最后面
	
	#set java env
	export JAVA_HOME=/export/servers/jdk/jdk1.8.0_141
	export JRE_HOME=${JAVA_HOME}/jre
	export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
	export PATH=${JAVA_HOME}/bin:$PATH
	
	保存
	使其生效:
	source /etc/profile
	看看是否成功:
	java -version
	
	rm –rf 文件夹目录是删除整个文件夹

## 4.如何在虚拟机上配置mysql

	在线下载mysql命令:
	yum install -y mysql-server
	启动mysql:
	service mysqld start
	开启之后:
	mysql 回车
	
	看看有哪些数据库:
	show databases;
	ctrl+c退出mysql
	关机:
	shutdown -h now
	
	配置第二台虚拟机时ip地址出错:
	cd /etc/udev/
	ll
	cd /rules.d
	ll
	删掉70-persistent-net.rules:
	rm /70-persistent-net.rules
	
	reboot
	计算机会重启
	Ifconfig还是没有ip
	
	cd /etc/udev/rules.d
	ls
	cat 70-persistent-net.rules
	新的网卡叫eth1
	
	改下配置
	vi 70-persistent-net.rules
	把NAME=”eth1”改成eth0 NAME=”eth0”
	
	vi ifcfg-eth0
	看看网络地址
	退出
	ll
	拷贝一下
	cat ifcfg-eth0

## 5.配置多台虚拟机
	cd /etc/udev/rules.d/
	cat 70-persistent-net.rules
	查看ATTR地址 查看NAME=?
	vi 70-persistent-net.rules
	改成eth0
	cd /etc/sysconfig/network-scripts/
	vi ifcfg-eth0
	先不用改BOOTPROTO
	cat ifcfg-eth0  查看HWADDR改成ATTR的地址
	
	service network restart
	ifconfig
	
	
	failse
	rm /etc/udev/rules.d/70-persistent-net.rules
	service network restart
	用Securel连
	
	修改
	cd /etc/sysconfig/network-scripts/
	vi ifcfg-eth0
	加上
	BOOTPROTO=static
	IPADDR=192.168.121.138
	NETMASK=255.255.255.0
	GATEWAY=192.168.121.2



# 二.环境搭建

## 1.修改hostname:
	vi /etc/hosts 添加多个 ip  主机名
	vi /etc/sysconfig/network 修改hostname

## 2：使用 CentOS 镜像创建本地 yum 源 
	1、挂载 iso 镜像，拷贝所有文件至本地 yum 目录 
	
	mkdir /dev/centios /mnt/local_yum 
	
	cd root/
	
	rz CentOS-6.7-x86_64-bin-DVD1.iso
	
	mount -o loop /root/CentOS-6.7-x86_64-bin-DVD1.iso /dev/centios 
	
	cp -r /dev/centios/* /mnt/local_yum/  
	
	2、修改 yum 源配置  
	
	cd /etc/yum.repos.d/  
	
	rename .repo .repo.bak *.repo 
	
	cp CentOS-Base.repo.bak CentOS-Local.repo 
	
	vi CentOS-Local.repo 
	
	[local_yum] 
	name=This is a local repo 
	baseurl=file:///mnt/local_yum 
	enabled=1  
	gpgcheck=1 
	gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6
	
	3、更新 yum 配置 
	
	yum clean all 
	
	yum repolist all   

## 3.通过httpd共享yum源

	查看httpd是否已安装
    # rpm -qa httpd
	安装及验证httpd  
    # yum -y install httpd
    # rpm -qa |grep httpd
    httpd-tools-2.2.15-29.el6.centos.x86_64
    httpd-2.2.15-29.el6.centos.x86_64
	启动httpd
	service httpd start
	此时出现ip地址,在browser上访问该地址
	其默认的存放路径在/var/www/html/路径下(相当于tomcat的webapp)
	cd /var/www/html/
	mkdir download
	把需要挂载的文件放到download文件夹里面
	访问ip/download就可以看到该文件了,下载即可
	
## 4.日志采集系统环境部署
	服务器中安装依赖 
	yum -y install gcc perl pcre-devel openssl openssl-devel  
	上传 LuaJIT-2.0.4.tar.gz 并安装 LuaJIT
	 tar -zxvf LuaJIT-2.0.4.tar.gz -C /usr/local/src/ cd /usr/local/src/LuaJIT-2.0.4/ make && make install PREFIX=/usr/local/luajit  
	设置 LuaJIT 环境变量 
	vi /etc/profile 
	export LUAJIT_LIB=/usr/local/luajit/lib
	export LUAJIT_INC=/usr/local/luajit/include/luajit-2.0
	 source   /etc/profile  
	创建 modules 文件夹，保存 nginx 依赖的模块 
	mkdir -p /usr/local/nginx/modules 
	cd  /usr/local/nginx/modules 
	上传 nginx 依赖的模块 
	set-misc-nginx-module-0.29.tar.gz
	lua-nginx-module-0.10.0.tar.gz 
	ngx_devel_kit-0.2.19.tar.gz
	echo-nginx-module-0.58.tar.gz  
	将依赖的模块直接解压到 modules 目录 
	tar -zxvf lua-nginx-module-0.10.0.tar.gz -C /usr/local/nginx/modules/
	tar -zxvf set-misc-nginx-module-0.29.tar.gz -C /usr/local/nginx/modules/
	tar -zxvf ngx_devel_kit-0.2.19.tar.gz -C /usr/local/nginx/modules/
	tar -zxvf echo-nginx-module-0.58.tar.gz -C /usr/local/nginx/modules/

	安装 openresty 
	tar -zxvf openresty-1.9.7.3.tar.gz -C /usr/local/src/
	cd /usr/local/src/openresty-1.9.7.3/ 
	./configure --prefix=/usr/local/openresty --with-luajit && make && make install    
	 
	安装 nginx 
	tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/src/  
	编译 nginx 并支持其他模块
	cd /usr/local/src/nginx-1.8.1/
  
	(一大段)

	./configure --prefix=/usr/local/nginx \
		--with-ld-opt="-Wl,-rpath,/usr/local/luajit/lib" \
		--add-module=/usr/local/nginx/modules/ngx_devel_kit-0.2.19 \
		--add-module=/usr/local/nginx/modules/lua-nginx-module-0.10.0 \
		--add-module=/usr/local/nginx/modules/set-misc-nginx-module-0.29 \
		--add-module=/usr/local/nginx/modules/echo-nginx-module-0.58

  

		make -j2

		make install

## 5.zookeeper分布式搭建
	
	安装前需要安装好jdk
	#### 记得关闭防火墙
	使用service iptables stop 关闭防火墙
	使用serv创建目录
	mkdir -p /export/software/
	#### 下载安装包、解压
	cd /export/software/
	tar -zxvf zookeeper-3.4.5.tar.gz
	mv zookeeper-3.4.5 zookeeper
	
	#### 修改环境变量（注意：3台zookeeper都需要修改）
	
	vi /etc/profile
	export ZOOKEEPER_HOME=/export/software/zookeeper
	export PATH=$PATH:$ZOOKEEPER_HOME/bin
	
	source /etc/profile
	
	#### 修改Zookeeper配置文件
	
	cd zookeeper/conf
	mv zoo_sample.cfg zoo.cfg
	vi zoo.cfg
	修改内容：
	dataDir=/export/data/zkpdata
	添加内容
	server.1=mini1:2888:3888     ## (心跳端口、选举端口)
	server.2=mini2:2888:3888
	server.3=mini3:2888:3888
	创建文件夹：
	cd /export/data/
	mkdir zkdata
	cd zkdata
	在data文件夹下新建myid文件，myid的文件内容为1：
	echo 1 > myid
	
	#### 分发安装包到其他机器(最好提前设置好面密登录  ssh-keygen -t rsa [dsa] 按四下回车   )
	scp -r /export/software/zookeeper/ root@vim02:/export/software/
	scp -r /export/software/zookeeper/ root@vim03:/export/software/
	
	#### 修改其他机器的配置文件
	修改myid文件
	到mini2上：修改myid为：2
	到mini3上：修改myid为：3
	
	#### 启动（每台机器!!!!!!!!!!!!!!!!!!只启动一台会失败!!!）
	/export/software/zookeeper/bin/zkServer.sh start
	
	还有 date 时间也要同步
	修改时间 date "时间"
	或者编写一个脚本来批量启动所有机器：
	for host in "mini1 mini2 mini3"
	do
	ssh $host "source/etc/profile;/root/apps/zookeeper/bin/zkServer.sh start"
	
	#### 查看集群状态
	jps（查看进程）
	zkServer.sh status（查看集群状态，主从信息）
	
	
	#### 出错时
	netstat -ntlp   //查看当前所有tcp端口·
	如果启动不成功，可以观察zookeeper.out日志，查看错误信息进行排查
	
	-----------------------------
	配置文件中参数说明:
	
	tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。
	
	initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。
	
	当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。
	
	syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。
	
	dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里；
	
	clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求；
	
	server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。


## 6.hadoop集群搭建(HDFS和Yarn集群)

#### 1.安装hadoop2.7.4
	上传hadoop的安装包到服务器
	 hadoop-2.7.4-with-centos-6.7.tar.gz
	 解压安装包
	 tar zxvf hadoop-2.7.4-with-centos-6.7.tar.gz
	
	注意：hadoop2.x的配置文件目录：$HADOOP_HOME/etc/hadoop
----------------------------------------------------------------------------------------------------------------	
#### 1.1修改hadoop配置文件
cd /$HADOOP_HOME/etc/hadoop
第一个：hadoop-env.sh
	
	vi hadoop-env.sh
	修改:
	export JAVA_HOME=/export/service/jdk
---------------------------------------------------------------------------		
第二个：core-site.xml

<!-- 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 -->
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://vim01:9000</value>
</property>

<!-- 指定hadoop运行时产生文件的存储目录,默认/tmp/hadoop-${user.name} -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/export/software/hadoop/tmp</value>
</property>
---------------------------------------------------------------------------			
第三个：hdfs-site.xml   

<!-- 指定HDFS副本的数量 默认为3个,此处修改为2个-->
<property>
	<name>dfs.replication</name>
	<value>2</value>
</property>
<!-- secondary namenode 所在主机的 ip 和端口-->    
<property>
 	<name>dfs.namenode.secondary.http-address</name>
  	<value>vim02:50090</value>
</property>

---------------------------------------------------------------------------			
第四个：mapred-site.xml 
		
mv mapred-site.xml.template mapred-site.xml
vi mapred-site.xml

<!-- 指定mr运行时框架，这里指定在yarn上，默认是local -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
---------------------------------------------------------------------------			
第五个：yarn-site.xml

<!-- 指定YARN的老大（ResourceManager）的地址 -->
<property>
	<name>yarn.resourcemanager.hostname</name>
	<value>vim01</value>
</property>
	
<!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序默认值："" -->
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>
---------------------------------------------------------------------------		 
第六个：slaves文件，里面写上从节点所在的主机名字

vi slaves
改为:
vim01
vim02
vim03
---------------------------------------------------------------------------	     	
#### 1.2将hadoop添加到环境变量
	
	vim /etc/proflie
		export HADOOP_HOME=/root/apps/hadoop-2.7.4
		export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

	source /etc/profile
---------------------------------------------------------------------------	  
	
#### 1.3第一次安装一定要格式化namenode（本质是对namenode进行初始化,只能格式化一次）
		hdfs namenode -format (hadoop namenode -format)
		
#### 1.4启动hadoop
		先启动HDFS
		sbin/
		start-dfs.sh
		
		再启动YARN
		sbin/
		start-yarn.sh
		
#### 1.5验证是否启动成功
		使用jps命令验证
		27408 NameNode
		28218 Jps
		27643 SecondaryNameNode   (secondarynamenode)
		28066 NodeManager
		27803 ResourceManager
		27512 DataNode
	
		http://192.168.1.101:50070 （HDFS管理界面）
		http://192.168.1.101:8088 （MR管理界面）
		
